{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77323f60",
   "metadata": {},
   "source": [
    "# Deep Learning Model( For Regression ):\n",
    "## CNN, CNN + RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53740a05",
   "metadata": {},
   "source": [
    "#### Case 1 : (CNN)\n",
    "- We take single image --> predict an angle\n",
    "- So here we are not using sequential information( not taking sequence of images )\n",
    "- We can have ConvNet based regression( just the loss will change ).\n",
    "\n",
    "#### Case 2 : (CNN + RNN)\n",
    "- Images + Seq      ----->   Angle + Sequence\n",
    "- input(Video)    ------>          Output(Seq of real numbers)\n",
    "- image ---> CNN---> [A vector]---> RNN(lstm)(many to many)---> yi\n",
    "\n",
    "- We will build CASE 1 model using ConvNet because we have limited computational resources for CASE 2 using CNN + RNN, and such models(case1) are called end to end models.\n",
    "\n",
    "- In Case 2, we might also have to define the window size correct. After we pass 45k photos through the CNN we get 45k vectors and their corresponding label. Now we can't pass 45k images at one go the LSTM model and create a 45k time step LSTM. We might define lets say 1 second as the window which means we create an LSTM of 30 timsteps(30 is the frame per second ). So the LSTM model is a many to many model with 30 inputs and 30 outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b60ddd",
   "metadata": {},
   "source": [
    "## Batch load the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17c9088",
   "metadata": {},
   "source": [
    "- Load data\n",
    "- Train and Test split (Temporal Split)\n",
    "- Batches of images ( using mini batch SGD )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "02d73d0e-f3eb-4ca7-aa77-b75f61d9fc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from scipy import pi\n",
    "from itertools import islice\n",
    "import random\n",
    "import scipy\n",
    "import scipy.misc\n",
    "import cv2\n",
    "\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "#pints to the end of the last batch\n",
    "train_batch_pointer = 0\n",
    "val_batch_pointer = 0\n",
    "\n",
    "#read data.txt\n",
    "with open(r\"C:\\Users\\sweta\\OneDrive\\Desktop\\DL Projects\\Self driving cars\\Autopilot\\driving_dataset\\data.txt\") as f:\n",
    "    for line in f:\n",
    "        xs.append(r\"C:\\Users\\sweta\\OneDrive\\Desktop\\DL Projects\\Self driving cars\\Autopilot\\driving_dataset/\" + line.split()[0])\n",
    "        ys.append(float(line.split()[1]) * scipy.pi / 180)\n",
    "\n",
    "#get number of images\n",
    "num_images = len(xs)\n",
    "\n",
    "train_xs = xs[:int(len(xs) * 0.8)]\n",
    "train_ys = ys[:int(len(ys) * 0.8)]\n",
    "                  \n",
    "val_xs = xs[-int(len(xs) * 0.2) :]   \n",
    "val_ys = ys[-int(len(ys) * 0.2) :]\n",
    "                  \n",
    "num_train_img = len(train_xs)\n",
    "num_val_img = len(val_xs)\n",
    "from PIL import Image\n",
    "def LoadTrainBatch(batch_size):\n",
    "    global train_batch_pointer\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(0, batch_size):\n",
    "        arr = cv2.imread(train_xs[(train_batch_pointer + i) % num_train_img])\n",
    "        img_road = arr[-150:]\n",
    "        img_road_resize = cv2.resize(img_road, (200, 66))\n",
    "        read_image_final = img_road_resize/255.0\n",
    "        x_out.append(read_image_final)\n",
    "        \n",
    "        y_out.append([train_ys[(train_batch_pointer + i) % num_train_img]])\n",
    "        \n",
    "    train_batch_pointer += batch_size\n",
    "    return x_out, y_out     \n",
    "def LoadValBatch(batch_size):\n",
    "    global val_batch_pointer\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(0, batch_size):        \n",
    "        arr = cv2.imread(val_xs[(val_batch_pointer + i) % num_val_img])\n",
    "        img_road = arr[-150:]\n",
    "        img_road_resize = cv2.resize(img_road, (200, 66))\n",
    "        read_image_final = img_road_resize/255.0\n",
    "        x_out.append(read_image_final)\n",
    "        \n",
    "        y_out.append([val_ys[(val_batch_pointer + i) % num_val_img]])\n",
    "        \n",
    "    val_batch_pointer += batch_size\n",
    "    return x_out, y_out   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
